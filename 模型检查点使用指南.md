# 📦 模型检查点使用指南

## 🎯 功能概述

该系统提供了完整的模型检查点功能，每200轮自动保存模型参数，支持训练中断后的恢复。

## ⚙️ 配置参数

在 `config.py` 中可以调整以下参数：

```python
# Model Checkpointing Settings (模型检查点设置)
ENABLE_MODEL_CHECKPOINTING = True  # 是否启用模型检查点保存
MODEL_SAVE_INTERVAL = 200          # 每多少个episode保存一次模型
CHECKPOINTS_DIR = "checkpoints"    # 模型检查点保存目录
```

## 📁 文件夹结构

训练过程中会自动创建如下结构：

```
checkpoints/
├── checkpoint_ep200_20250817_143052/
│   ├── agent_0.pth           # 智能体0的完整参数
│   ├── agent_1.pth           # 智能体1的完整参数
│   ├── agent_2.pth           # 智能体2的完整参数
│   ├── agent_3.pth           # 智能体3的完整参数
│   ├── agent_4.pth           # 智能体4的完整参数
│   ├── training_state.pth    # 训练状态（噪声、奖励历史等）
│   └── config_info.txt       # 可读的配置信息
├── checkpoint_ep400_20250817_151234/
│   └── ...
└── checkpoint_ep600_20250817_155678/
    └── ...
```

## 🔍 检查点内容

### **智能体参数文件 (`agent_i.pth`)**
每个智能体文件包含：
- **网络参数**：Actor、Critic、目标网络的所有权重
- **优化器状态**：Adam优化器的momentum等状态
- **Transformer参数**：端到端学习的Transformer权重
- **学习率信息**：当前学习率状态

### **训练状态文件 (`training_state.pth`)**
包含：
- 当前episode数
- 噪声衰减状态
- 历史奖励记录
- 训练进度百分比
- 完整的配置参数

### **配置信息文件 (`config_info.txt`)**
人类可读的文本文件，包含：
```
模型检查点信息
==================================================
保存时间: 20250817_143052
训练轮数: 200
训练进度: 6.7%
当前噪声: 0.832456
环境类型: full
随机种子: 123
智能体数量: 5
近期平均奖励: 1245.67

训练配置参数:
  NUM_EPISODES: 3000
  BATCH_SIZE: 512
  LR_ACTOR: 5e-05
  ...
```

## 🚀 使用方法

### **1. 自动保存**
启动训练后，系统会自动每200轮保存一次：

```bash
python main.py
```

训练日志中会显示：
```
💾 模型检查点已保存: checkpoints/checkpoint_ep200_20250817_143052
   包含: 5个智能体 + 训练状态 + 配置信息
```

### **2. 手动加载检查点**
如果需要从检查点恢复训练，可以在代码中添加：

```python
# 在main.py的智能体创建之后添加
if 从检查点恢复:
    checkpoint_path = "checkpoints/checkpoint_ep200_20250817_143052"
    training_state = load_model_checkpoint(agents, checkpoint_path, device)
    
    # 恢复训练状态
    if training_state:
        start_episode = training_state['episode']
        noise_std = training_state['noise_std']
        episode_rewards_log = training_state['episode_rewards_log']
        print(f"📂 从第{start_episode}轮恢复训练")
```

### **3. 模型评估和推理**
使用保存的检查点进行推理：

```python
# 加载训练好的模型用于推理
checkpoint_path = "checkpoints/checkpoint_ep2000_20250817_183052"
training_state = load_model_checkpoint(agents, checkpoint_path, device)

# 设置为评估模式
for agent in agents:
    agent.eval()

# 进行推理
with torch.no_grad():
    action = agents[0].act(state, point_features, other_obs, noise_std=0.0)
```

## 💾 磁盘空间管理

### **存储空间估计**
每个检查点大小约：
- 每个智能体：~10-50MB（取决于网络大小）
- 总检查点：~50-250MB
- 每200轮保存一次，3000轮训练约需要：3.75GB

### **清理旧检查点**
可以手动删除旧的检查点文件夹来释放空间：

```bash
# 只保留最近3个检查点
cd checkpoints
ls -t | tail -n +4 | xargs rm -rf
```

### **选择性保存**
如果想减少存储，可以调整保存频率：

```python
# config.py
MODEL_SAVE_INTERVAL = 500  # 每500轮保存一次，减少存储需求
```

## 🔧 故障排除

### **常见问题**

**1. 检查点保存失败**
```
检查磁盘空间是否充足
确认checkpoints目录有写权限
```

**2. 加载检查点时出错**
```
确认检查点路径正确
检查PyTorch版本兼容性
确认设备类型匹配（CPU/GPU）
```

**3. 训练中断后恢复**
```python
# 查找最新的检查点
import os
import glob

checkpoints = glob.glob("checkpoints/checkpoint_ep*")
latest_checkpoint = max(checkpoints, key=os.path.getctime)
print(f"最新检查点: {latest_checkpoint}")
```

## 🎯 最佳实践

1. **定期备份**：将关键检查点复制到其他位置
2. **监控磁盘空间**：长期训练时注意存储空间
3. **记录实验**：在config_info.txt中查看训练参数
4. **版本标记**：重要实验的检查点可以重命名保存

## 📊 与TensorBoard结合使用

检查点功能与TensorBoard完美配合：
1. **保存时间点**：在TensorBoard中标记保存的episode
2. **性能对比**：加载不同检查点对比性能
3. **调试分析**：从特定检查点继续训练进行调试

现在您的训练系统具备了完整的模型版本管理能力！🚀
