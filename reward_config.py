"""
å¢é‡å¼å¥–åŠ±å®éªŒé…ç½®ç³»ç»Ÿ

è¿™ä¸ªæ¨¡å—å…è®¸æ‚¨é€æ­¥å¼€å¯ä¸åŒçš„å¥–åŠ±ç»„ä»¶ï¼Œç³»ç»Ÿåœ°åˆ†ææ¯ä¸ªå¥–åŠ±æ¨¡å—å¯¹åä½œç­–ç•¥çš„å½±å“ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä» BASIC å¼€å§‹è®­ç»ƒï¼Œç¡®ä¿åŸºç¡€æ”¶æ•›
2. é€æ­¥å‡çº§åˆ°æ›´å¤æ‚çš„é…ç½® 
3. è§‚å¯Ÿæ¯ä¸ªæ–°å¢æ¨¡å—å¯¹åä½œæŒ‡æ ‡çš„å½±å“

å®éªŒæµç¨‹å»ºè®®ï¼š
BASIC â†’ LOAD_EFFICIENCY â†’ ROLE_SPECIALIZATION â†’ COLLABORATION â†’ BEHAVIOR_SHAPING â†’ FULL
"""

class RewardExperimentConfig:
    """å¢é‡å¼å¥–åŠ±å®éªŒé…ç½®"""
    
    # å®éªŒé…ç½®ç­‰çº§å®šä¹‰
    BASIC = "basic"                    # åŸºç¡€ï¼šåªæœ‰é‡‡é›†å¥–åŠ±
    LOAD_EFFICIENCY = "load_efficiency"       # è½½é‡æ•ˆç‡ï¼š+æ»¡è½½å¥–åŠ±
    ROLE_SPECIALIZATION = "role_specialization"   # è§’è‰²ä¸“ä¸šåŒ–ï¼š+å¿«é€Ÿ/é‡è½½æ™ºèƒ½ä½“ä¸“ä¸šåŒ–
    COLLABORATION = "collaboration"           # åä½œï¼š+å†²çªè§£å†³å’Œåä½œå¥–åŠ±
    BEHAVIOR_SHAPING = "behavior_shaping"     # è¡Œä¸ºå¡‘é€ ï¼š+æ¥è¿‘å¥–åŠ±å’Œæ™ºèƒ½è¡Œä¸º
    FULL = "full"                     # å®Œæ•´ç‰ˆï¼šæ‰€æœ‰å¥–åŠ±æ¨¡å—
    
    def __init__(self, experiment_level=BASIC):
        """
        åˆå§‹åŒ–å¥–åŠ±é…ç½®
        
        Args:
            experiment_level: å®éªŒç­‰çº§ï¼Œä»BASICåˆ°FULL
        """
        self.experiment_level = experiment_level
        self._setup_reward_modules()
    
    def _setup_reward_modules(self):
        """æ ¹æ®å®éªŒç­‰çº§è®¾ç½®å¯ç”¨çš„å¥–åŠ±æ¨¡å—"""
        
        # æ‰€æœ‰å¥–åŠ±æ¨¡å—çš„å¼€å…³
        self.enable_basic_rewards = True  # åŸºç¡€å¥–åŠ±ï¼šæ°¸è¿œå¯ç”¨
        self.enable_load_efficiency = False
        self.enable_role_specialization = False  
        self.enable_collaboration = False
        self.enable_behavior_shaping = False
        self.enable_advanced_penalties = False
        
        # æ ¹æ®å®éªŒç­‰çº§é€æ­¥å¯ç”¨æ¨¡å—
        if self.experiment_level in [self.LOAD_EFFICIENCY, self.ROLE_SPECIALIZATION, 
                                    self.COLLABORATION, self.BEHAVIOR_SHAPING, self.FULL]:
            self.enable_load_efficiency = True
            
        if self.experiment_level in [self.ROLE_SPECIALIZATION, self.COLLABORATION, 
                                    self.BEHAVIOR_SHAPING, self.FULL]:
            self.enable_role_specialization = True
            
        if self.experiment_level in [self.COLLABORATION, self.BEHAVIOR_SHAPING, self.FULL]:
            self.enable_collaboration = True
            
        if self.experiment_level in [self.BEHAVIOR_SHAPING, self.FULL]:
            self.enable_behavior_shaping = True
            
        if self.experiment_level == self.FULL:
            self.enable_advanced_penalties = True
    
    def get_reward_constants(self):
        """è·å–å½“å‰å®éªŒç­‰çº§å¯¹åº”çš„å¥–åŠ±å¸¸é‡"""
        
        # åŸºç¡€å¥–åŠ±å¸¸é‡ï¼ˆæ°¸è¿œå¯ç”¨ï¼‰
        constants = {
            # === åŸºç¡€å¥–åŠ±æ¨¡å— ===
            'R_COLLECT_BASE': 50.0,           # é‡‡é›†åŸºç¡€å¥–åŠ±
            'R_RETURN_HOME_COEFF': 0.5,       # å›å®¶å¥–åŠ±ç³»æ•°
            'P_TIME_STEP': -0.1,              # æ—¶é—´æ­¥æƒ©ç½š
            'P_ENERGY_DEPLETED': -50.0,       # èƒ½é‡ä¸è¶³æƒ©ç½š
            'FINAL_BONUS_ACCOMPLISHED': 1000.0, # æœ€ç»ˆå®Œæˆå¥–åŠ±
            
            # === è½½é‡æ•ˆç‡æ¨¡å— ===
            'R_FULL_LOAD_BONUS': 300.0 if self.enable_load_efficiency else 0.0,
            'R_ROLE_CAPACITY_BONUS': 50.0 if self.enable_load_efficiency else 0.0,
            'P_EMPTY_RETURN': -20.0 if self.enable_load_efficiency else 0.0,
            'P_LOW_LOAD_HEAVY_AGENT': -15.0 if self.enable_load_efficiency else 0.0,
            
            # === è§’è‰²ä¸“ä¸šåŒ–æ¨¡å— ===
            'R_FAST_AGENT_HIGH_PRIORITY': 30.0 if self.enable_role_specialization else 0.0,
            'R_ROLE_SPEED_BONUS': 20.0 if self.enable_role_specialization else 0.0,
            'P_HEAVY_AGENT_HIGH_PRIORITY': -15.0 if self.enable_role_specialization else 0.0,
            
            # === åä½œæ¨¡å— ===
            'R_COLLAB_HIGH_PRIORITY': 20.0 if self.enable_collaboration else 0.0,
            'P_CONFLICT': -2.0 if self.enable_collaboration else 0.0,
            
            # === è¡Œä¸ºå¡‘é€ æ¨¡å— ===
            'R_COEFF_APPROACH_TASK': 0.1 if self.enable_behavior_shaping else 0.0,
            'R_COEFF_APPROACH_HOME_LOADED': 0.05 if self.enable_behavior_shaping else 0.0,
            'R_COEFF_APPROACH_HOME_LOW_ENERGY': 0.1 if self.enable_behavior_shaping else 0.0,
            'R_STAY_HOME_AFTER_COMPLETION': 10.0 if self.enable_behavior_shaping else 0.0,
            'R_SMART_RETURN_AFTER_COMPLETION': 50.0 if self.enable_behavior_shaping else 0.0,
            'REWARD_SHAPING_CLIP': 10.0 if self.enable_behavior_shaping else 0.0,
            
            # === é«˜çº§æƒ©ç½šæ¨¡å— ===
            'P_INVALID_TASK_ATTEMPT': -100.0 if self.enable_advanced_penalties else -10.0,
            'P_OVERLOAD_ATTEMPT': -80.0 if self.enable_advanced_penalties else -10.0,
            'P_TIMEOUT_BASE': -30.0 if self.enable_advanced_penalties else -5.0,
            'P_INACTIVITY': -10.0 if self.enable_advanced_penalties else 0.0,
            'P_NOT_RETURN_AFTER_COMPLETION': -20.0 if self.enable_advanced_penalties else 0.0,
            'P_POINTLESS_ACTION': -20.0 if self.enable_advanced_penalties else 0.0,
        }
        
        return constants
    
    def get_experiment_description(self):
        """è·å–å½“å‰å®éªŒç­‰çº§çš„æè¿°"""
        descriptions = {
            self.BASIC: "åŸºç¡€å®éªŒï¼šåªæœ‰é‡‡é›†å¥–åŠ±å’ŒåŸºç¡€æƒ©ç½šï¼ŒéªŒè¯æ™ºèƒ½ä½“èƒ½å¦å­¦ä¼šåŸºæœ¬ä»»åŠ¡é‡‡é›†",
            self.LOAD_EFFICIENCY: "è½½é‡æ•ˆç‡å®éªŒï¼š+æ»¡è½½å¥–åŠ±å’Œç©ºè½½æƒ©ç½šï¼Œå­¦ä¹ é«˜æ•ˆè½½é‡ç­–ç•¥",
            self.ROLE_SPECIALIZATION: "è§’è‰²ä¸“ä¸šåŒ–å®éªŒï¼š+å¿«é€Ÿ/é‡è½½æ™ºèƒ½ä½“ä¸“ä¸šåŒ–å¥–åŠ±ï¼Œå­¦ä¹ åˆ†å·¥åä½œ",
            self.COLLABORATION: "åä½œå®éªŒï¼š+å†²çªè§£å†³å’Œåä½œå¥–åŠ±ï¼Œå­¦ä¹ é¿å…å†²çªå’Œåä½œç­–ç•¥",
            self.BEHAVIOR_SHAPING: "è¡Œä¸ºå¡‘é€ å®éªŒï¼š+æ¥è¿‘å¥–åŠ±å’Œæ™ºèƒ½è¡Œä¸ºå¥–åŠ±ï¼Œå­¦ä¹ ç²¾ç»†åŒ–è¡Œä¸ºæ¨¡å¼",
            self.FULL: "å®Œæ•´å®éªŒï¼šæ‰€æœ‰å¥–åŠ±æ¨¡å—ï¼Œå­¦ä¹ æœ€å¤æ‚çš„åä½œç­–ç•¥"
        }
        return descriptions.get(self.experiment_level, "æœªçŸ¥å®éªŒç­‰çº§")
    
    def get_expected_behaviors(self):
        """è·å–å½“å‰ç­‰çº§é¢„æœŸå­¦ä¼šçš„è¡Œä¸º"""
        behaviors = {
            self.BASIC: [
                "åŸºç¡€ä»»åŠ¡é‡‡é›†",
                "èƒ½é‡ç®¡ç†ï¼ˆé¿å…èƒ½é‡è€—å°½ï¼‰",
                "åŸºç¡€è¿”å›åŸºåœ°è¡Œä¸º"
            ],
            self.LOAD_EFFICIENCY: [
                "ä¼˜åŒ–è½½é‡åˆ©ç”¨ç‡",
                "é¿å…ç©ºè½½è¿”å›",
                "æ»¡è½½æ—¶ä¸»åŠ¨è¿”å›åŸºåœ°"
            ],
            self.ROLE_SPECIALIZATION: [
                "å¿«é€Ÿæ™ºèƒ½ä½“ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§ä»»åŠ¡",
                "é‡è½½æ™ºèƒ½ä½“ä¸“æ³¨å¤„ç†å¤§è½½é‡ä»»åŠ¡",
                "æ ¹æ®æ™ºèƒ½ä½“ç±»å‹é€‰æ‹©åˆé€‚ä»»åŠ¡"
            ],
            self.COLLABORATION: [
                "é¿å…ä»»åŠ¡å†²çª",
                "æ™ºèƒ½å†²çªè§£å†³",
                "åä½œå¤„ç†é«˜ä¼˜å…ˆçº§ä»»åŠ¡"
            ],
            self.BEHAVIOR_SHAPING: [
                "è·¯å¾„ä¼˜åŒ–ï¼ˆæ¥è¿‘å¥–åŠ±å¼•å¯¼ï¼‰",
                "ä»»åŠ¡å®Œæˆåçš„æ™ºèƒ½è¡Œä¸ºé€‰æ‹©",
                "ç²¾ç»†åŒ–çš„çŠ¶æ€æ„ŸçŸ¥è¡Œä¸º"
            ],
            self.FULL: [
                "å¤æ‚çš„å¤šæ™ºèƒ½ä½“åä½œç­–ç•¥",
                "é«˜çº§çš„ä»»åŠ¡åˆ†é…ä¼˜åŒ–",
                "å…¨é¢çš„æ•ˆç‡å’Œåä½œå¹³è¡¡"
            ]
        }
        return behaviors.get(self.experiment_level, [])
    
    def get_key_metrics(self):
        """è·å–å½“å‰ç­‰çº§çš„å…³é”®è¯„ä¼°æŒ‡æ ‡"""
        metrics = {
            self.BASIC: [
                "ä»»åŠ¡å®Œæˆç‡",
                "å¹³å‡episodeé•¿åº¦", 
                "èƒ½é‡åˆ©ç”¨æ•ˆç‡"
            ],
            self.LOAD_EFFICIENCY: [
                "è½½é‡åˆ©ç”¨ç‡",
                "ç©ºè½½è¿”å›æ¬¡æ•°",
                "æ»¡è½½å¥–åŠ±è·å¾—æ¬¡æ•°"
            ],
            self.ROLE_SPECIALIZATION: [
                "å¿«é€Ÿæ™ºèƒ½ä½“é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ¯”ä¾‹",
                "é‡è½½æ™ºèƒ½ä½“è½½é‡æ•ˆç‡",
                "è§’è‰²ä¸“ä¸šåŒ–å·®è·"
            ],
            self.COLLABORATION: [
                "å†²çªç‡",
                "å†²çªè§£å†³æˆåŠŸç‡",
                "åä½œä»»åŠ¡å®Œæˆæ•ˆç‡"
            ],
            self.BEHAVIOR_SHAPING: [
                "è·¯å¾„æ•ˆç‡",
                "æ™ºèƒ½è¡Œä¸ºå¥–åŠ±è·å¾—æƒ…å†µ",
                "ç²¾ç»†åŒ–è¡Œä¸ºæ¨¡å¼è¯„åˆ†"
            ],
            self.FULL: [
                "ç»¼åˆåä½œæ•ˆç‡",
                "å¤šç»´åº¦å¹³è¡¡è¯„åˆ†",
                "å¤æ‚ç­–ç•¥å­¦ä¹ æˆåŠŸç‡"
            ]
        }
        return metrics.get(self.experiment_level, [])

# é¢„å®šä¹‰çš„å®éªŒé…ç½®å®ä¾‹
EXPERIMENT_CONFIGS = {
    RewardExperimentConfig.BASIC: RewardExperimentConfig(RewardExperimentConfig.BASIC),
    RewardExperimentConfig.LOAD_EFFICIENCY: RewardExperimentConfig(RewardExperimentConfig.LOAD_EFFICIENCY),
    RewardExperimentConfig.ROLE_SPECIALIZATION: RewardExperimentConfig(RewardExperimentConfig.ROLE_SPECIALIZATION),
    RewardExperimentConfig.COLLABORATION: RewardExperimentConfig(RewardExperimentConfig.COLLABORATION),
    RewardExperimentConfig.BEHAVIOR_SHAPING: RewardExperimentConfig(RewardExperimentConfig.BEHAVIOR_SHAPING),
    RewardExperimentConfig.FULL: RewardExperimentConfig(RewardExperimentConfig.FULL),
}

def print_experiment_guide():
    """æ‰“å°å®éªŒæŒ‡å¯¼"""
    from utils import debug_print
    
    debug_print("\n" + "ğŸ§ª" * 60)
    debug_print("å¢é‡å¼å¥–åŠ±å®éªŒæŒ‡å¯¼")
    debug_print("ğŸ§ª" * 60)
    
    for level in [RewardExperimentConfig.BASIC, RewardExperimentConfig.LOAD_EFFICIENCY,
                  RewardExperimentConfig.ROLE_SPECIALIZATION, RewardExperimentConfig.COLLABORATION,
                  RewardExperimentConfig.BEHAVIOR_SHAPING, RewardExperimentConfig.FULL]:
        
        config = EXPERIMENT_CONFIGS[level]
        debug_print(f"\nğŸ“Š å®éªŒç­‰çº§: {level.upper()}")
        debug_print(f"   æè¿°: {config.get_experiment_description()}")
        debug_print(f"   é¢„æœŸè¡Œä¸º: {', '.join(config.get_expected_behaviors())}")
        debug_print(f"   å…³é”®æŒ‡æ ‡: {', '.join(config.get_key_metrics())}")
    
    debug_print("\nğŸ’¡ å®éªŒå»ºè®®:")
    debug_print("   1. æŒ‰é¡ºåºè¿›è¡Œå®éªŒï¼Œç¡®ä¿æ¯ä¸ªç­‰çº§éƒ½èƒ½æ”¶æ•›")
    debug_print("   2. è®°å½•æ¯ä¸ªç­‰çº§çš„å…³é”®æŒ‡æ ‡å˜åŒ–")
    debug_print("   3. å¯¹æ¯”ä¸åŒç­‰çº§çš„åä½œç­–ç•¥å·®å¼‚")
    debug_print("   4. åˆ†æå¥–åŠ±æ¨¡å—å¯¹æœ€ç»ˆæ€§èƒ½çš„è´¡çŒ®")
    debug_print("ğŸ§ª" * 60)

if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    print_experiment_guide()
