# 11G显存优化配置建议

## 🎯 建议的批量大小设置

基于您的11G显存，我推荐以下配置选项：

### 🚀 推荐配置（已应用）
```python
BATCH_SIZE = 512  # 建议设置
```

### 📊 其他可选配置

| 配置等级 | BATCH_SIZE | 显存占用估算 | 适用场景 |
|---------|------------|-------------|----------|
| 保守 | 384 | ~4-5GB | 确保稳定，留出调试空间 |
| **推荐** | **512** | **~6-7GB** | **平衡性能和稳定性** |
| 激进 | 768 | ~8-9GB | 最大化批量大小 |
| 极限 | 1024 | ~10-11GB | 可能接近显存上限 |

## ⚡ 性能优化建议

### 1. 批量大小的影响
- **更大批量**：
  ✅ 梯度估计更稳定
  ✅ 更好的GPU利用率
  ✅ 可能更快的收敛
  ❌ 显存占用更高

### 2. 监控指标
运行时注意观察：
- GPU显存使用率（建议<90%）
- 训练速度（batch/sec）
- 收敛稳定性

### 3. 如果出现显存不足
按以下顺序调整：
1. 降低到 `BATCH_SIZE = 384`
2. 降低到 `BATCH_SIZE = 256`（原始值）
3. 考虑使用梯度累积

## 🔧 进阶优化选项

### 梯度累积（如果需要更大有效批量）
```python
# 在main.py中可以实现
EFFECTIVE_BATCH_SIZE = 1024
ACTUAL_BATCH_SIZE = 512
ACCUMULATION_STEPS = EFFECTIVE_BATCH_SIZE // ACTUAL_BATCH_SIZE  # 2
```

### 混合精度训练（实验性）
```python
# 可以节省约30-40%显存
# 需要在网络前向传播中使用autocast
```

## 📈 预期性能提升

从256→512批量大小的预期改进：
- 🔄 训练速度：+20-30%
- 📊 收敛稳定性：+15-25%
- 🎯 最终性能：+5-10%

## ⚠️ 注意事项

1. **首次运行监控**：密切关注显存使用情况
2. **学习率调整**：更大批量可能需要稍微调整学习率
3. **回退方案**：如有问题可随时改回256

## 🚀 测试建议

建议先运行一个短期实验测试：
```bash
# 修改config.py中NUM_EPISODES = 100 进行测试
python main.py
```

如果显存使用正常，再运行完整的批量实验。
