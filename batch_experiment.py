"""
æ‰¹é‡å®éªŒè„šæœ¬ - å¤šç§å­å¢é‡å¼å¥–åŠ±å®éªŒ

è¿™ä¸ªè„šæœ¬è‡ªåŠ¨è¿è¡Œæ‰€æœ‰å®éªŒç­‰çº§çš„å¤šç§å­å®éªŒï¼Œç¡®ä¿ç»“æœçš„ç»Ÿè®¡å¯é æ€§ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. é…ç½®å®éªŒå‚æ•°
2. è¿è¡Œè„šæœ¬ï¼špython batch_experiment.py
3. ç­‰å¾…æ‰€æœ‰å®éªŒå®Œæˆ
4. ä½¿ç”¨å¤šç§å­åˆ†æå™¨åˆ†æç»“æœ

æ³¨æ„ï¼šå®Œæ•´å®éªŒå¯èƒ½éœ€è¦æ•°å°æ—¶æˆ–æ•°å¤©æ—¶é—´ï¼Œå»ºè®®åœ¨æ€§èƒ½è‰¯å¥½çš„æœºå™¨ä¸Šè¿è¡Œã€‚
"""

import os
import subprocess
import time
import json
from datetime import datetime, timedelta
from pathlib import Path

from reward_config import RewardExperimentConfig
from utils import debug_print

class BatchExperimentRunner:
    """æ‰¹é‡å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, 
                 seeds=[42, 123, 2024, 888, 1337],
                 experiment_levels=None,
                 episodes_per_experiment=2000,
                 results_dir="multi_seed_results"):
        """
        åˆå§‹åŒ–æ‰¹é‡å®éªŒè¿è¡Œå™¨
        
        Args:
            seeds: éšæœºç§å­åˆ—è¡¨
            experiment_levels: å®éªŒç­‰çº§åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºè¿è¡Œæ‰€æœ‰ç­‰çº§
            episodes_per_experiment: æ¯ä¸ªå®éªŒçš„è®­ç»ƒå›åˆæ•°
            results_dir: ç»“æœå­˜å‚¨ç›®å½•
        """
        self.seeds = seeds
        self.episodes_per_experiment = episodes_per_experiment
        self.results_dir = results_dir
        
        # é»˜è®¤è¿è¡Œæ‰€æœ‰å®éªŒç­‰çº§
        if experiment_levels is None:
            self.experiment_levels = [
                RewardExperimentConfig.BASIC,
                RewardExperimentConfig.LOAD_EFFICIENCY,
                RewardExperimentConfig.ROLE_SPECIALIZATION,
                RewardExperimentConfig.COLLABORATION,
                RewardExperimentConfig.BEHAVIOR_SHAPING,
                RewardExperimentConfig.FULL
            ]
        else:
            self.experiment_levels = experiment_levels
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        
        # å®éªŒçŠ¶æ€è·Ÿè¸ª
        self.experiment_log = []
        self.start_time = None
        self.total_experiments = len(self.seeds) * len(self.experiment_levels)
        
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        debug_print("ğŸš€ å¼€å§‹æ‰¹é‡å¢é‡å¼å¥–åŠ±å®éªŒ")
        debug_print("=" * 80)
        debug_print(f"ğŸ“Š å®éªŒé…ç½®:")
        debug_print(f"   ç§å­æ•°é‡: {len(self.seeds)}")
        debug_print(f"   å®éªŒç­‰çº§: {len(self.experiment_levels)}")
        debug_print(f"   æ€»å®éªŒæ•°: {self.total_experiments}")
        debug_print(f"   æ¯å®éªŒå›åˆæ•°: {self.episodes_per_experiment}")
        debug_print(f"   ç»“æœç›®å½•: {self.results_dir}")
        debug_print("=" * 80)
        
        self.start_time = datetime.now()
        completed_experiments = 0
        
        for level in self.experiment_levels:
            debug_print(f"\nğŸ§ª å¼€å§‹å®éªŒç­‰çº§: {level.upper()}")
            debug_print("-" * 60)
            
            for seed in self.seeds:
                debug_print(f"\nğŸ² è¿è¡Œç§å­: {seed}")
                
                try:
                    # è®°å½•å®éªŒå¼€å§‹
                    exp_start_time = datetime.now()
                    
                    # è¿è¡Œå•ä¸ªå®éªŒ
                    success = self._run_single_experiment(level, seed)
                    
                    # è®°å½•å®éªŒç»“æœ
                    exp_end_time = datetime.now()
                    duration = exp_end_time - exp_start_time
                    
                    if success:
                        debug_print(f"âœ… å®éªŒå®Œæˆ (è€—æ—¶: {duration})")
                        completed_experiments += 1
                    else:
                        debug_print(f"âŒ å®éªŒå¤±è´¥ (è€—æ—¶: {duration})")
                    
                    # è®°å½•åˆ°æ—¥å¿—
                    self.experiment_log.append({
                        'level': level,
                        'seed': seed,
                        'success': success,
                        'start_time': exp_start_time.isoformat(),
                        'end_time': exp_end_time.isoformat(),
                        'duration_seconds': duration.total_seconds()
                    })
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (completed_experiments / self.total_experiments) * 100
                    remaining = self.total_experiments - completed_experiments
                    if completed_experiments > 0:
                        avg_time_per_exp = (datetime.now() - self.start_time) / completed_experiments
                        estimated_remaining_time = avg_time_per_exp * remaining
                        debug_print(f"ğŸ“ˆ è¿›åº¦: {completed_experiments}/{self.total_experiments} ({progress:.1f}%)")
                        debug_print(f"â±ï¸ é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining_time}")
                    
                except Exception as e:
                    debug_print(f"ğŸ’¥ å®éªŒå¼‚å¸¸: {e}")
                    self.experiment_log.append({
                        'level': level,
                        'seed': seed,
                        'success': False,
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    })
        
        # ä¿å­˜å®éªŒæ—¥å¿—
        self._save_experiment_log()
        
        # è¾“å‡ºæ€»ç»“
        total_time = datetime.now() - self.start_time
        success_rate = (completed_experiments / self.total_experiments) * 100
        
        debug_print("\n" + "ğŸ‰" * 80)
        debug_print("æ‰¹é‡å®éªŒå®Œæˆæ€»ç»“")
        debug_print("ğŸ‰" * 80)
        debug_print(f"âœ… æˆåŠŸå®Œæˆ: {completed_experiments}/{self.total_experiments} ({success_rate:.1f}%)")
        debug_print(f"â±ï¸ æ€»è€—æ—¶: {total_time}")
        debug_print(f"ğŸ“ ç»“æœç›®å½•: {self.results_dir}")
        debug_print(f"ğŸ“Š ä¸‹ä¸€æ­¥: è¿è¡Œ python multi_seed_analyzer.py åˆ†æç»“æœ")
        debug_print("ğŸ‰" * 80)
        
        return completed_experiments, self.total_experiments
    
    def _run_single_experiment(self, level, seed):
        """
        è¿è¡Œå•ä¸ªå®éªŒ
        
        Args:
            level: å®éªŒç­‰çº§
            seed: éšæœºç§å­
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # é¢„å…ˆåˆ›å»ºç‹¬ç«‹çš„å®éªŒç›®å½•
            exp_output_dir = self._prepare_experiment_directory(level, seed)
            
            # ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ŒæŒ‡å®šè¾“å‡ºç›®å½•
            self._update_config(level, seed, exp_output_dir)
            
            # è¿è¡Œä¸»ç¨‹åº
            debug_print(f"   ğŸ“‹ é…ç½®: ç­‰çº§={level}, ç§å­={seed}, å›åˆ={self.episodes_per_experiment}")
            debug_print(f"   ğŸ“ è¾“å‡ºç›®å½•: {exp_output_dir}")
            
            result = subprocess.run(
                ["python", "main.py"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                debug_print(f"   âœ… è®­ç»ƒå®Œæˆ")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                self._cleanup_temp_files()
                return True
            else:
                debug_print(f"   âŒ è®­ç»ƒå¤±è´¥: {result.stderr}")
                return False
                

        except Exception as e:
            debug_print(f"   ğŸ’¥ è¿è¡Œå¼‚å¸¸: {e}")
            return False
    
    def _prepare_experiment_directory(self, level, seed):
        """
        ä¸ºå®éªŒé¢„å…ˆåˆ›å»ºç‹¬ç«‹çš„ç›®å½•ç»“æ„
        
        Args:
            level: å®éªŒç­‰çº§
            seed: éšæœºç§å­
            
        Returns:
            str: å®éªŒè¾“å‡ºç›®å½•è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åˆ›å»ºå®éªŒç‰¹å®šç›®å½•
        exp_name = f"{level}_seed{seed}_{timestamp}"
        exp_dir = os.path.join(self.results_dir, level, exp_name)
        
        # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„å­ç›®å½•
        os.makedirs(exp_dir, exist_ok=True)
        os.makedirs(os.path.join(exp_dir, "reward_plots"), exist_ok=True)
        os.makedirs(os.path.join(exp_dir, "trajectories"), exist_ok=True)
        
        debug_print(f"   ğŸ“ å·²åˆ›å»ºå®éªŒç›®å½•: {exp_dir}")
        
        return exp_dir
    
    def _cleanup_temp_files(self):
        """æ¸…ç†å¯èƒ½æ®‹ç•™çš„ä¸´æ—¶æ–‡ä»¶"""
        temp_files = [
            "rewards_log.npy",
            "collaboration_analytics.npy"
        ]
        
        for filename in temp_files:
            if os.path.exists(filename):
                try:
                    os.remove(filename)
                    debug_print(f"   ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {filename}")
                except Exception as e:
                    debug_print(f"   âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}")
    
    def _update_config(self, level, seed, output_dir):
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        config_content = f"""# Environment Settings
NUM_POINTS = 30  #ä»»åŠ¡ç‚¹æ•°é‡
NUM_AGENTS = 5

# Training Settings
NUM_EPISODES = {self.episodes_per_experiment}  # è®­ç»ƒå›åˆæ•°
MAX_NUM_STEPS = 1500 # æœ€å¤§æ­¥æ•°

BATCH_SIZE = 512 # æ‰¹é‡å¤§å° - é’ˆå¯¹11Gæ˜¾å­˜ä¼˜åŒ–
GAMMA = 0.999
UPDATE_EVERY = 1
CAPACITY = 100000 # ç»éªŒå›æ”¾å®¹é‡

# Learning Rates
LR_ACTOR = 5e-5 # æ¼”å‘˜åˆå§‹å­¦ä¹ ç‡
LR_CRITIC = 5e-4 # æ‰¹è¯„å®¶åˆå§‹å­¦ä¹ ç‡

# Learning Rate Scheduling Settings
ENABLE_LR_SCHEDULING = True  # æ˜¯å¦å¯ç”¨å­¦ä¹ ç‡è°ƒåº¦
LR_DECAY_TYPE = "exponential"  # å­¦ä¹ ç‡è¡°å‡ç±»å‹: "exponential", "step", "cosine"
LR_DECAY_RATE = 0.995  # æŒ‡æ•°è¡°å‡ç‡ (æ¯æ¬¡æ›´æ–°ä¹˜ä»¥æ­¤å€¼)
LR_DECAY_EPISODES = 100  # æ¯å¤šå°‘å›åˆè¿›è¡Œä¸€æ¬¡å­¦ä¹ ç‡è¡°å‡
LR_MIN_RATIO = 0.1  # æœ€å°å­¦ä¹ ç‡æ¯”ä¾‹ (æœ€å°å­¦ä¹ ç‡ = åˆå§‹å­¦ä¹ ç‡ * æ­¤æ¯”ä¾‹)
LR_WARMUP_EPISODES = 50  # å­¦ä¹ ç‡é¢„çƒ­å›åˆæ•°

# Exploration Noise Settings
NOISE_STD_START = 1.0 # åˆå§‹å™ªå£°æ ‡å‡†å·®
NOISE_STD_END = 0.01 # æœ€ç»ˆå™ªå£°æ ‡å‡†å·®
NOISE_DECAY = 0.995 # è®©å™ªå£°è¡°å‡å¾—æ›´æ…¢ï¼Œç»™äºˆæ›´å¤šæ¢ç´¢æ—¶é—´

# Prioritized Experience Replay Settings  
PER_ALPHA = 0.6  # ä¼˜å…ˆçº§æŒ‡æ•°ï¼ˆ0=å‡åŒ€é‡‡æ ·ï¼Œ1=å®Œå…¨æŒ‰ä¼˜å…ˆçº§é‡‡æ ·ï¼‰
PER_BETA = 0.4   # é‡è¦æ€§é‡‡æ ·æƒé‡æŒ‡æ•°ï¼ˆ0=æ— æƒé‡ï¼Œ1=å®Œå…¨è¡¥å¿ï¼‰
PER_BETA_INCREMENT = 0.001  # betaçš„å¢é•¿ç‡
PER_EPSILON = 1e-6  # é¿å…é›¶ä¼˜å…ˆçº§çš„å°å€¼

# Intelligent Conflict Resolution Settings
ICR_PRIORITY_WEIGHT = 1.0      # ä»»åŠ¡ä¼˜å…ˆçº§æƒé‡
ICR_AGENT_TYPE_WEIGHT = 1.0    # æ™ºèƒ½ä½“ç±»å‹åŒ¹é…æƒé‡
ICR_DISTANCE_WEIGHT = 0.6      # è·ç¦»æ•ˆç‡æƒé‡
ICR_LOAD_WEIGHT = 0.4          # è½½é‡åˆ©ç”¨ç‡æƒé‡
ICR_URGENCY_WEIGHT = 0.8       # æ—¶é—´ç´§è¿«åº¦æƒé‡
ICR_ENERGY_WEIGHT = 0.2        # èƒ½é‡æ•ˆç‡æƒé‡

# Visualization Settings
RENDER_INTERVAL = 1000 # æ¸²æŸ“é—´éš”

# Debug Settings
DEBUG_PRINT = False  # True=å¯ç”¨æ‰“å°è¾“å‡º, False=å…³é—­æ‰“å°è¾“å‡º

# Random Seed Settings
RANDOM_SEED = {seed}  # éšæœºç§å­ï¼Œç”¨äºç¡®ä¿å®éªŒå¯é‡ç°æ€§
# æ¨èçš„å®éªŒç§å­é›†: [42, 123, 2024, 888, 1337]

# Communication Settings
ENABLE_IMMEDIATE_COMMUNICATION = False  # True=å³æ—¶é€šä¿¡(t), False=å»¶è¿Ÿé€šä¿¡(t-1)

# Environment Settings
ENVIRONMENT_TYPE = "configurable"  # "configurable"=å¯é…ç½®å¥–åŠ±ç¯å¢ƒ, "simplified"=ç®€åŒ–ç¯å¢ƒ, "full"=å®Œæ•´ç¯å¢ƒ
# USE_SIMPLIFIED_ENVIRONMENT = False  # å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ENVIRONMENT_TYPE

# Agent Architecture Settings
USE_ENHANCED_CRITIC = True  # True=Criticæ¥æ”¶æ‰€æœ‰æ™ºèƒ½ä½“åŠ¨ä½œä¿¡æ¯(å®éªŒæ€§), False=æ ‡å‡†MADDPG

# Incremental Reward Experiment Settings
from reward_config import RewardExperimentConfig
REWARD_EXPERIMENT_LEVEL = RewardExperimentConfig.{level.upper()}  # å¢é‡å¼å¥–åŠ±å®éªŒç­‰çº§
# å¯é€‰ç­‰çº§: BASIC, LOAD_EFFICIENCY, ROLE_SPECIALIZATION, COLLABORATION, BEHAVIOR_SHAPING, FULL

# Output Directory Settings (ç”¨äºæ‰¹é‡å®éªŒ)
OUTPUT_DIR = r"{output_dir}"  # å®éªŒè¾“å‡ºç›®å½•
REWARD_PLOTS_DIR = r"{os.path.join(output_dir, 'reward_plots')}"  # å¥–åŠ±æ›²çº¿å›¾ç›®å½•
TRAJECTORIES_DIR = r"{os.path.join(output_dir, 'trajectories')}"  # è½¨è¿¹å›¾ç›®å½•

# æ™ºèƒ½ä½“å‚æ•°
agent_capacity = [10, 10, 10, 20, 20]  # æ™ºèƒ½ä½“è½½é‡å®¹é‡
agent_speed = [40, 40, 40, 8, 8]  # æ™ºèƒ½ä½“ç§»åŠ¨é€Ÿåº¦ - æ‰©å¤§åˆ°5å€å·®è·
agent_energy_max = [80000, 80000, 80000, 120000, 120000]  # æ™ºèƒ½ä½“æœ€å¤§èƒ½é‡ï¼ˆæ›´ä¸¥æ ¼çš„è®¾ç½®ï¼‰
fast_charge_time = 3 * 60#å¿«é€Ÿå……ç”µæ—¶é—´
slow_charge_time = 8 * 60#æ…¢é€Ÿå……ç”µæ—¶é—´
"""
        
        with open("config.py", "w", encoding="utf-8") as f:
            f.write(config_content)
    

    def _save_experiment_log(self):
        """ä¿å­˜å®éªŒæ—¥å¿—"""
        log_file = os.path.join(self.results_dir, "experiment_log.json")
        
        log_data = {
            'start_time': self.start_time.isoformat(),
            'end_time': datetime.now().isoformat(),
            'total_experiments': self.total_experiments,
            'seeds': self.seeds,
            'experiment_levels': self.experiment_levels,
            'episodes_per_experiment': self.episodes_per_experiment,
            'experiments': self.experiment_log
        }
        
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        
        debug_print(f"ğŸ“ å®éªŒæ—¥å¿—å·²ä¿å­˜: {log_file}")

def run_quick_test():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆå°‘æ•°ç§å­å’Œå›åˆï¼‰"""
    debug_print("ğŸ§ª è¿è¡Œå¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    
    runner = BatchExperimentRunner(
        seeds=[42, 123],  # åªç”¨2ä¸ªç§å­
        experiment_levels=[
            RewardExperimentConfig.BASIC,
            RewardExperimentConfig.LOAD_EFFICIENCY
        ],  # åªæµ‹è¯•2ä¸ªç­‰çº§
        episodes_per_experiment=500,  # è¾ƒå°‘çš„å›åˆæ•°
        results_dir="quick_test_results"
    )
    
    return runner.run_all_experiments()

def run_full_experiments():
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    debug_print("ğŸš€ è¿è¡Œå®Œæ•´å®éªŒæ¨¡å¼")
    
    runner = BatchExperimentRunner(
        seeds=[42, 123, 2024, 888, 1337],  # 5ä¸ªç§å­
        experiment_levels=None,  # æ‰€æœ‰ç­‰çº§
        episodes_per_experiment=3000,  # å®Œæ•´å›åˆæ•°
        results_dir="full_experiment_results"
    )
    
    return runner.run_all_experiments()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ‰¹é‡å¢é‡å¼å¥–åŠ±å®éªŒ")
    parser.add_argument("--mode", choices=["quick", "full"], default="quick",
                       help="å®éªŒæ¨¡å¼: quick=å¿«é€Ÿæµ‹è¯•, full=å®Œæ•´å®éªŒ")
    
    args = parser.parse_args()
    
    if args.mode == "quick":
        run_quick_test()
    else:
        run_full_experiments()
